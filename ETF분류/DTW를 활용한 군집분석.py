# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_2DEx36T7F4P3aFkASQ--M4wbLfe2fCF
"""

import pandas as pd

2
# Suppress warnings and logging messages
data = '/content/drive/MyDrive/NH/(etf 스코어 정리)score백분위, min-max scaling 포함 데이터.csv'
etf_score_df = pd.read_csv(data)
#본선 데이터 로드
etf_score_df = pd.read_csv(data).apply(lambda x: x.str.strip() if x.dtype == "object" else x)  # ETF 점수 정보 테이블
etf_score_df['bse_dt'] = pd.to_datetime(etf_score_df['bse_dt'])

etf_score_df

"""데이터 전처리

모든 etf_iem_cd 항목에서 겹치는 bse_dt찾기
"""

# 모든 etf_iem_cd 항목에 대해 중복된 bse_dt 찾기
grouped_data = etf_score_df.groupby('bse_dt')['etf_iem_cd'].nunique().reset_index()
common_dates = grouped_data[grouped_data['etf_iem_cd'] > 1]['bse_dt']

# 해당 bse_dt를 가진 모든 행 필터링
common_data = etf_score_df[etf_score_df['bse_dt'].isin(common_dates)].sort_values(by='bse_dt')

# 결과 출력
print("모든 etf_iem_cd 항목에 대해 중복된 bse_dt:")
print(common_data[['etf_iem_cd', 'bse_dt']].drop_duplicates().sort_values(by=['bse_dt', 'etf_iem_cd']))

output_path = '/content/drive/MyDrive/NH/filtered_common_data.csv'
common_data.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

data1 = '/content/drive/MyDrive/NH/filtered_common_data.csv'
filtered_data = pd.read_csv(data1)
filtered_data

"""etf_iem_cd와 bse_dt 별로 정렬"""

filtered_data = filtered_data.sort_values(by=['etf_iem_cd', 'bse_dt'])

"""그룹화 - 총 61일 중, 5일씩 12그룹으로 나누기, 마지막 그룹은 6개로 처리



"""

import numpy as np
filtered_data['group'] = filtered_data.groupby('etf_iem_cd').cumcount() // 5
filtered_data['group'] = np.where(filtered_data.groupby('etf_iem_cd')['group'].transform('max') == filtered_data['group'],
                                  filtered_data['group'], filtered_data['group'] + 1)

output_path = '/content/drive/MyDrive/NH/filter1.csv'
filtered_data.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""그룹별로 합치면서, 값은 평균값으로 설정"""

columns_of_interest = ['mm1_tot_pft_rt', 'mm3_tot_pft_rt', 'yr1_tot_pft_rt',
                       'etf_sor_100', 'crr_z_sor_100', 'mxdd_z_sor_100', 'vty_z_sor_100']
grouped_means = filtered_data.groupby(['etf_iem_cd', 'group'])[columns_of_interest].mean().reset_index()
grouped_means

output_path = '/content/drive/MyDrive/NH/final.csv'
grouped_means.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""가독성을 위해 소수점 3자리까지만 표기"""

grouped_means_rounded = grouped_means.round(decimals=3)
grouped_means_rounded.head(5)

output_path = '/content/drive/MyDrive/NH/final2.csv'
grouped_means_rounded.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""군집화한 것을 기존 etf_score_df에 결합"""

grouped_means_with_sector = pd.merge(
    grouped_means_rounded,
    filtered_data[['etf_iem_cd', 'group', 'etf_sector_nm']].drop_duplicates(),
    on=['etf_iem_cd', 'group'],
    how='left')

output_path = '/content/drive/MyDrive/NH/finalfinal.csv'
grouped_means_with_sector.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""분석중 사라진, sector_nm 넣기"""

cols = grouped_means_with_sector.columns.tolist()
cols.insert(1, cols.pop(cols.index('etf_sector_nm')))  # Moving 'etf_sector_nm' to the second position
grouped_means_reordered = grouped_means_with_sector[cols]

output_path = '/content/drive/MyDrive/NH/3final.csv'
grouped_means_reordered.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""시계열 데이터에 대한 dtw 유사도 거리 분석을 위해

etf_iem_cd 항목별로 수직이 아닌 수평으로 나열
"""

# Group the data to spread each metric horizontally for each group while keeping `etf_iem_cd` and `etf_sector_nm`
reshaped_data_horizontal = grouped_means_reordered.pivot_table(
    index=['etf_iem_cd', 'etf_sector_nm'],
    columns='group',
    values=[col for col in grouped_means_reordered.columns if col not in ['etf_iem_cd', 'etf_sector_nm', 'group']]
)

# Flatten the column names to form a single-level DataFrame with column names as 'metric_group'
reshaped_data_horizontal.columns = [f"{metric}_{group}" for metric, group in reshaped_data_horizontal.columns]
reshaped_data_horizontal = reshaped_data_horizontal.reset_index()

reshaped_data_horizontal.head(5)

output_path = '/content/drive/MyDrive/NH/data.csv'
reshaped_data_horizontal.to_csv(output_path, index=False)

print(f"Data saved successfully at {output_path}")

"""DTW 거리 행렬 계산"""

data1 = pd.read_csv('/content/drive/MyDrive/NH/data.csv')
col = data1.columns

import pandas as pd
import numpy as np
from dtaidistance import dtw
from scipy.cluster.hierarchy import linkage, fcluster
import matplotlib.pyplot as plt
import seaborn as sns

# 1. 데이터 불러오기
file_path = '/content/drive/MyDrive/NH/data.csv'  # 실제 경로로 수정
etf_data = pd.read_csv(file_path, index_col=0)

# 'etf_sector_nm' 열 제거
if 'etf_sector_nm' in etf_data.columns:
    etf_data = etf_data.drop(columns=['etf_sector_nm'])

# DTW 거리 행렬 초기화
n = etf_data.shape[0]
distance_matrix = np.zeros((n, n))

# DTW 거리 계산
for i in range(n):
    for j in range(i + 1, n):
        dist = dtw.distance(etf_data.iloc[i, :], etf_data.iloc[j, :])  # 각 시계열 간 DTW 거리 계산
        distance_matrix[i, j] = dist
        distance_matrix[j, i] = dist  # 대칭성을 활용하여 반대 방향에도 동일한 값 할당
# 변수명(열 이름) 확인
print("Column names in the dataset:")
print(etf_data.columns)

# 결과 출력
print("DTW Distance Matrix:")
print(distance_matrix)

# 결과를 DataFrame으로 변환 및 저장
distance_df = pd.DataFrame(distance_matrix, index=etf_data.index, columns=etf_data.index)
output_path = '/content/drive/MyDrive/NH/dtw_distance_matrix.csv'  # 저장할 경로 수정
distance_df.to_csv(output_path)

print(f"DTW 거리 행렬이 '{output_path}' 경로에 저장되었습니다.")

"""elbow method를 spectral clustering해서 4개의 군집으로 나누기

"""

import pandas as pd
import numpy as np
from sklearn.cluster import SpectralClustering
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# 데이터 불러오기
file_path = '/content/drive/MyDrive/NH/dtw_distance_matrix.csv'
distance_matrix = pd.read_csv(file_path, index_col=0)

# Spectral Clustering 모델 생성 및 학습 (클러스터 수 4개)
n_clusters = 4
spectral_clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=0)
labels = spectral_clustering.fit_predict(distance_matrix)

# 클러스터링 결과 추가
distance_matrix['Cluster'] = labels
print("Spectral Clustering 결과 (4개 클러스터):")
print(distance_matrix['Cluster'].value_counts())

"""etf_score_df 데이터에 적용"""

# 'etf_iem_cd'를 기준으로 클러스터링 결과 할당
# 가정: distance_matrix의 인덱스가 `etf_data`의 `etf_iem_cd`와 일치하는 순서로 되어 있음
etf_score_df['군집'] = etf_score_df['etf_iem_cd'].map(dict(zip(distance_matrix.index, labels)))

# NaN 값을 처리하기 위해 필요시 설정 (중복 없는 항목은 특정 기본값으로 설정 가능)
etf_score_df['군집'] = etf_score_df['군집'].fillna(-1)  # -1로 기본값 설정 (필요에 따라 변경 가능)

etf_score_df

output_path = '/content/drive/MyDrive/NH/etf1.csv'  # 저장할 경로 수정
etf_score_df.to_csv(output_path)

print(f"군집추가csv가 '{output_path}' 경로에 저장되었습니다.")

"""각 변수별 boxplot 시각화"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 불러오기
file_path = '/content/drive/MyDrive/NH/etf1.csv'
etf_data = pd.read_csv(file_path)

# 필요한 칼럼 목록
columns_to_plot = ['mm1_tot_pft_rt', 'mm3_tot_pft_rt', 'yr1_tot_pft_rt',
                   'etf_sor_100', 'crr_z_sor_100', 'mxdd_z_sor_100', 'vty_z_sor_100']

# 'bse_dt'를 datetime 형식으로 변환 후, 군집별로 가장 최근 5개 데이터 선택
etf_data['bse_dt'] = pd.to_datetime(etf_data['bse_dt'])
latest_data = etf_data.sort_values('bse_dt').groupby('군집').tail(5)

# 각 군집별 평균 데이터 생성
mean_data = latest_data.groupby('군집')[columns_to_plot].mean().reset_index()

# Boxplot 생성 (쨍한 색상으로 설정)
colors = ['red', 'blue', 'lime', 'magenta']  # 쨍한 색상 목록
for column in columns_to_plot:
    plt.figure(figsize=(8, 5))
    boxplot_data = [latest_data[latest_data['군집'] == cluster][column] for cluster in mean_data['군집']]
    bp = plt.boxplot(boxplot_data, patch_artist=True, labels=mean_data['군집'], widths=0.4)  # 박스 폭 줄임

    # 박스 색상 설정
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)

    # 중앙값 선을 검정색으로 설정
    for median in bp['medians']:
        median.set_color('black')
        median.set_linewidth(2)

    plt.title(f'Boxplot of {column} by Cluster')
    plt.xlabel('Cluster')
    plt.ylabel(column)

    # 그래프를 PNG 파일로 저장
    output_file_path = f'/content/drive/MyDrive/NH/사진/{column}_boxplot.png'
    plt.savefig(output_file_path, format='png')
    plt.close()  # 그래프를 닫아 메모리 절약